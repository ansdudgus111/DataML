# 으뜸 데이터 분석과 머신러닝

## Chapter 01 : 빅데이터와 데이터 분석의 중요성
### 1.1 빅데이터와 데이터 분석
### 1.2 점점 더 중요해지고 있는 데이터의 가치
### 1.3 데이터 분석 플랫폼과 데이터 시장의 형성
### 1.4 인류 최대의 도전 - 블랙홀 관측과 데이터 분석
### 1.5 이 책에서 배울 데이터 분석을 위한 도구

## Chapter 02 : 데이터과학을 위한 개발도구
### 2.1 데이터 분석과 머신러닝을 위한 강력한 프로그래밍 언어 : 파이썬
### 2.2 모듈의 개념과 활용
### 2.3 모듈의 활용과 패키지 설치하기
### 2.4 파이썬의 강력한 패키지들
### 2.5 아나콘다 개발도구를 설치하고 사용해 보자
### 2.6 주피터 노트북의 여러 가지 기능들
### 2.7 주피터 노트북의 셀과 코드입력
### 2.8 주피터 노트북의 작동방식
### 2.9 IPython을 사용해보자
### 2.10 IPython에서 제공하는 마법 명령어
### 2.11 데이터 과학자들의 의사소통을 도와주는 마크다운
### 2.12 알아두면 편리한 고급 마크다운 기능과 명령 모드
### 2.13 클라우드 환경의 개발은 코랩으로 편리하게
### 2.14 코랩은 구글 리눅스 가상머신에서 동작한다
### 2.15 코랩 디스크 마운트하고 파일 올리기
### 2.16 코랩 디스크의 내용 확인하기

## Chapter 03 : 파이썬 최고의 라이브러리 : 넘파이
### 3.1 파이썬 리스트와 넘파이
### 3.2 다차원 배열의 속성들
### 3.3 다차원 배열과 브로드캐스팅
### 3.4 연속적인 값을 가지는 다차원 배열의 생성
### 3.5 다차원 배열의 축과 삽입
### 3.6 파이썬 리스트 vs 넘파이 다차원 배열
### 3.7 넘파이 배열의 인덱싱과 슬라이싱
### 3.8 다차원 배열의 최대값, 최소값, 평균값 구하기와 정렬
### 3.9 다차원 배열을 위한 append() 함수와 행렬 곱셈
### 3.10 과학자들이 사랑하는 수: 난수
### 3.11 다양한 난수 만들기 함수를 살펴보자
### 3.12 넘파이 스타일의 슬라이싱과 논리 인덱싱
### 3.13 넘파이는 왜 성공했나
### 3.14 벡터화 연산의 성능을 측정해 보자
### 3.15 리덕션 : 배열을 더 강력하게 만드는 기능
### 3.16 선형방정식을 풀어보자
### 3.17 배열의 결합 concatenate, vstack, hstack
### 3.18 배열을 결합하는 r_, c_ 클래스와 column_stack() 함수

## Chapter 04 : 데이터 시각화 도구 맷플롯립
### 4.1 데이터 과학과 효과적인 시각화의 필요성
### 4.2 데이터 과학을 위한 시각화 도구 matplotlib
### 4.3 plot() 함수의 선 그리기 기능들을 알아보자
### 4.4 복잡한 선을 그리고 이미지로 저장하자
### 4.5 제목과 레이블, 스타일에 대해 알아보자
### 4.6 Figure, axes에 대하여 살펴보자
### 4.7 subplot()의 고급 기능
### 4.8 자료값의 분포를 나타내는 산점도와 막대 그래프
### 4.9 파이 차트와 히트맵 표현
### 4.10 히스토그램
### 4.11 히스토그램을 이용한 정규 분포 함수와 확률 밀도 함수 그리기
### 4.12 상자 수염 그리기
### 4.13 그래프의 크기와 그리드 그리기

## Chapter 05 : 통계 데이터와 시본 라이브러리
### 5.1 데이터 사이의 관련성을 알아보자
### 5.2 상관계수를 구하고 시각화를 하도록 하자
### 5.3 특성 간의 관련성을 알려주는 상관계수와 쌍 그래프
### 5.4 시본 라이브러리 시작하기
### 5.5 tips 데이터와 여러 가지 시각화 방법
### 5.6 산점도 그래프로 관계를 상세하게 나타내보자
### 5.7 변수 사이의 관계를 알아보기에 편리한 쌍 그래프
### 5.8 Anscombe’s quartet 데이터 셋을 알아보자
### 5.9 비선형 함수를 사용하여 데이터를 설명하자
### 5.10 시본의 또 다른 데이터 셋 : flights 데이터 셋

## Chapter 06 : 엑셀보다 판다스
### 6.1 엑셀보다 빠르고 강력한 판다스
### 6.2 데이터 교환을 위한 csv 파일 형식
### 6.3 판다스의 기본 구조인 시리즈와 데이터프레임
### 6.4 csv 데이터를 읽고 확인하기
### 6.5 데이터프레임의 구조
### 6.6 새로운 열을 생성하자
### 6.7 inplace로 데이터프레임 갱신하기
### 6.8 데이터프레임 시각화
### 6.9 편리하고 강력한 시각화
### 6.10 편리한 데이터 다루기 - 슬라이싱과 인덱싱
### 6.11 loc, iloc 인덱서
### 6.12 판다스를 이용한 기상 데이터 분석
### 6.13 데이터 정제와 결손값의 처리
### 6.14 시계열 자료 분석을 위한 DatetimeIndex
### 6.15 그룹핑과 필터링
### 6.16 데이터 구조를 변경하는 pivot()
### 6.17 두 개의 데이터프레임을 하나로 합치는 concat()
### 6.18 테이블 데이터의 결합: concat()과 merge()

## Chapter 07 : 머신러닝 기초 : 사이킷런과 선형 회귀
### 7.1 경험을 통해서 학습하는 인간을 통해 지능을 정의해 보자
### 7.2 머신러닝의 정의와 종류를 알아보자
### 7.3 회귀분석과 독립변수, 종속변수
### 7.4 사이킷런을 이용한 선형 회귀
### 7.5 선형 회귀 모델의 계수와 절편
### 7.6 간단한 선형 회귀를 수행해 보자
### 7.7 데이터를 시각화하고 차원을 증가시키자
### 7.8 가설의 정확도를 평가하는 오차
### 7.9 오차 함수의 구현과 파라미터 공간의 최적값
### 7.10 미분과 경사 하강법
### 7.11 경사 하강법과 학습의 원리
### 7.12 경사 하강법과 학습률

## Chapter 08 : 다중 회귀와 규제
### 8.1 변수가 여러 개인 공간에서의 회귀분석
### 8.2 캐글 데이터를 이용해서 분석해 보자
### 8.3 기대수명 데이터 둘러보기
### 8.4 기대수명과 상관도가 높은 데이터는 무엇인가
### 8.5 기대수명과 특성 분석
### 8.6 훈련 데이터, 검증 데이터 그리고 특성
### LAB 8-1 상관도를 시각화하여 중요 특성을 분석하자
### 8.7 데이터의 분포가 직선이 아니라면? 다항 회귀 모델을 사용하자
### 8.8 다항 회귀 모델을 사용하자
### LAB 8-2 3차 방정식을 만들고 다항 회귀 모델을 이용하여 예측하기
### 8.9 과대 적합에 주의하자
### 8.10 과소 적합, 과대 적합, 그리고 규제
### 8.11 최적화와 릿지 회귀
### 8.12 릿지 회귀와 alpha 값

## Chapter 09 : 분류와 군집화
### 9.1 분류와 군집화
### 9.2 k-NN 알고리즘에 사용할 견종의 표본 집합 시각화
### 9.3 k-NN 분류기를 실행하자
### 9.4 k-NN 활용 예제 - 붓꽃 데이터 준비하기
### 9.5 k-NN 활용 예제 - 붓꽃 데이터로 학습하기
### 9.6 새로운 꽃에 대해서 모델을 적용하고 분류해 보자
### 9.7 게임을 하는 고객을 분류해 보자
### 9.8 데이터 전처리의 필요성
### 9.9 데이터 정규화 방법을 이용하자
### 9.10 다양한 스케일러 살펴보기 

## Chapter 10 : 다양한 머신러닝 기법 - SVM, 결정 트리, 차원 축소
### 10.1 서포트 벡터 머신의 소개
### 10.2 서포트 벡터 머신의 구현 방법
### 10.3 분류 오류와 마진 오류 최소화 사이의 트레이드오프
### 10.4 서포트 벡터 머신을 파이프라인을 사용하여 구현해 보기
### 10.5 많은 데이터에 대하여 서포트 벡터 머신으로 분류하기
### 10.6 결정 트리와 분류
### 10.7 엔트로피를 계산해보자
### 10.8 엔트로피 곡면과 정보 이득
### 10.9 불순도를 이용한 의사결정 트리 - CART 알고리즘
### 10.10 결정 트리 구현해 보기
### 10.11 차원의 저주
### 10.12 차원 축소
### 10.13 3차원 공간의 데이터에서 주성분 찾기
### 10.14 4차원 공간에 존재하는 붓꽃 데이터를 2차원에서 분류해 보자

## Chapter 11 : 신경망과 퍼셉트론
### 11.1 인간 뇌의 비밀
### 11.2 단순한 퍼셉트론의 구조를 살펴보자
### 11.3 신경망을 만들기 위한 간단한 행렬 표현법
### 11.4 AND와 OR 회로를 퍼셉트론으로 만들자
### 11.5 퍼셉트론을 학습시키자
### 11.6 퍼셉트론을 학습시키는 알고리즘을 구현하자
### 11.7 인공지능의 겨울 : 퍼셉트론의 한계와 XOR 문제
### 11.8 다층 퍼셉트론으로 XOR 연산을 하자
### 11.9 오차 역전파를 개략적으로 살펴보자
### 11.10 다양한 활성화 함수

## Chapter 12 : 텐서플로로 따라하는 딥러닝
### 12.1 가장 인기 있는 머신러닝, 딥러닝 플랫폼 : 텐서플로
### 12.2 MNIST 데이터 가져오기
### 12.3 MNIST 데이터 그리기
### 12.4 심층 신경망 모델을 만들고 하이퍼파라미터를 튜닝하자
### 12.5 인공 신경망을 학습시켜 보자
### 12.6 인공 신경망의 성능을 개선해 보자
### 12.7 새 이미지를 잘 학습하는가 알아보자
### 12.8 부드러운 최대값을 출력하는 소프트맥스 함수
### 12.9 직접 만든 이미지를 업로드하고 테스트하자
### 12.10 데이터의 전처리는 매우 중요하다
### 12.11 붓꽃 데이터의 분류에 도전하자
### 12.12 분류 정확도를 높이기 위한 층을 추가하자
### 12.13 학습한 모델을 저장하고 불러오자
### 12.14 수치값을 예측하는 딥러닝 모델

## Chapter 13 : 합성곱 신경망
### 13.1 고급 데이터 : 패션 MNIST
### 13.2 패션 MNIST 데이터 학습시키기
### 13.3 수용장과 합성곱 신경망
### 13.4 합성곱과 필터
### 13.5 이미지 불러오기와 흐림 필터 적용하기
### 13.6 경계를 검출하기 위한 필터들
### 13.7 합성곱 신경망의 기본적인 구조
### 13.8 패딩과 스트라이드
### 13.9 합성곱 신경망을 위한 채널과 풀링의 개념
### 13.10 풀링을 하는 이유
### 13.11 합성곱 신경망의 최종 단계 : 평탄화
### 13.12 합성곱 신경망 모델을 만들어 보자
### 13.13 합성곱 신경망 모델을 훈련시키고 성능을 알아보자
### 13.14 합성곱 신경망 모델의 결과를 시각화하자
### 13.15 교차 검증과 드롭아웃
### 13.16 온라인 시각화 사이트를 이용하자
### 13.17 범용 인공지능과 인공지능
